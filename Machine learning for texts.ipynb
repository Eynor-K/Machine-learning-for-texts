{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH3MDnrJqWVa"
   },
   "source": [
    "# Wikishop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzTkzzRlqeG4"
   },
   "source": [
    "**Цель проекта:**\n",
    "Построить модель, которая будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l25GcZOqsx4"
   },
   "source": [
    "**План проекта:**\n",
    "1. Загрузка данных;\n",
    "2. Подготовка данных;\n",
    "3. Обучение моделей;\n",
    "4. Выбор лучшей модели;\n",
    "5. Общие выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meVMPTyZx7BN"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGoQQRxrzXx1",
    "outputId": "36722409-2f56-4489-a746-e88a8b003f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (from catboost) (5.4.0)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.9/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly->catboost) (8.0.1)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: dill\n",
      "Successfully installed dill-0.3.8\n"
     ]
    }
   ],
   "source": [
    "# установка бибилеотек\n",
    "\n",
    "!pip install catboost\n",
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jTC8_rkoqvmm"
   },
   "outputs": [],
   "source": [
    "# импорт бибилеотек\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import dill as pickle\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFU5-4PD50tb",
    "outputId": "72287466-204c-4e18-f7d0-57e2fa480465"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8B05Egejqyvu"
   },
   "outputs": [],
   "source": [
    "# чтение данных\n",
    "data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col=[0])\n",
    "\n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upMcT8fJx0cp",
    "outputId": "a3d06443-aeeb-4dca-9571-dfdb61aad77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Os93C7JqyIp_",
    "outputId": "b871736f-a7d5-497e-8a42-3e6128b45d95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "_oIZ7MjD0XMl",
    "outputId": "15178b44-1b46-4d7a-a5f8-cd5e8174c93e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-GJb50p0mTI"
   },
   "source": [
    "### Выводы:\n",
    "- Данные не сбалансированы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvByJ7-70FAW"
   },
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m7GSQ_EzcUUc"
   },
   "outputs": [],
   "source": [
    "# Определение функции для преобразования POS-тегов\n",
    "def get_wordnet_pos(tag):\n",
    "    tag = tag[0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v1aZUBg40Ngv"
   },
   "outputs": [],
   "source": [
    "# Функция для лемматизации текста\n",
    "def lemmatize(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Получаем POS-теги для всех токенов\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Лемматизация с использованием POS-тегов\n",
    "    lemm_text = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(tag))\n",
    "        for token, tag in pos_tags\n",
    "    ]\n",
    "\n",
    "    # Очистка текста от символов\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', ' '.join(lemm_text))\n",
    "    return \" \".join(cleared_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yychWa_phjoo"
   },
   "outputs": [],
   "source": [
    "# Применение параллельной обработки к каждому тексту\n",
    "def parallel_lemmatization(texts):\n",
    "    return Parallel(n_jobs=-1, backend=\"multiprocessing\", verbose=5)(delayed(lemmatize)(text) for text in texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "0lUeK7M73UBm",
    "outputId": "c2b85149-ad82-41c3-fd5f-82e41a1965a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n t make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                          lemm_text\n",
       "0      0  explanation why the edits make under my userna...\n",
       "1      0  d aww he match this background colour i m seem...\n",
       "2      0  hey man i m really not try to edit war it s ju...\n",
       "3      0  more i ca n t make any real suggestion on impr...\n",
       "4      0  you sir be my hero any chance you remember wha..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# Применение лемматизации к текстам с использованием параллельной обработки\n",
    "data['lemm_text'] = parallel_lemmatization(data['text'].tolist())\n",
    "\n",
    "# Удаление исходного столбца 'text'\n",
    "data = data.drop(columns=['text'])\n",
    "\n",
    "# Проверка результата\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-QC6Z36g2gja"
   },
   "outputs": [],
   "source": [
    "# Получение стоп-слов и преобразование в список\n",
    "stopwords = list(nltk_stopwords.words('english'))\n",
    "\n",
    "# Инициализация TfidfVectorizer с корректным списком стоп-слов\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DVhhGKkw1sms"
   },
   "outputs": [],
   "source": [
    "# Разделение данных\n",
    "X = data.drop(columns=['toxic'])\n",
    "y = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Применение TF-IDF векторизации к обучающей и тестовой выборке\n",
    "X_train = count_tf_idf.fit_transform(X_train['lemm_text'])\n",
    "X_test = count_tf_idf.transform(X_test['lemm_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ved12VSqvTqY"
   },
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbWC_UqwvW6T"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K78WI4_Q7K6P",
    "outputId": "2f2a3a83-88da-4574-a5e2-ceb410c8db6b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:\n",
      "{'C': 10, 'solver': 'liblinear'}\n",
      "F1 для LogisticRegression = 0.76\n"
     ]
    }
   ],
   "source": [
    "# Определение модели логистической регрессии с учетом дисбаланса классов\n",
    "model_lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Гиперпараметры для поиска\n",
    "hyperparams = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# GridSearchCV с метрикой F1\n",
    "clf_lr = GridSearchCV(\n",
    "    model_lr,\n",
    "    hyperparams,\n",
    "    scoring='f1',  # Используем F1 как метрику для оценки модели\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "# Вывод лучших гиперпараметров\n",
    "print(\"Лучшие гиперпараметры:\")\n",
    "print(clf_lr.best_params_)\n",
    "\n",
    "# Лучшая модель\n",
    "model_lr = clf_lr.best_estimator_\n",
    "\n",
    "# Оценка F1-метрики\n",
    "f1_lr = clf_lr.best_score_\n",
    "\n",
    "print('F1 для LogisticRegression =', f1_lr.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YnZ4xLWwowq"
   },
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNqU1zIQvtdy",
    "outputId": "d6a375fd-4cbd-4552-beaa-d7b5eba2d637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 20}\n",
      "F1 для DecisionTreeClassifier = 0.6\n"
     ]
    }
   ],
   "source": [
    "# Определение модели дерева решений с учетом дисбаланса классов\n",
    "model_dtc = DecisionTreeClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Расширенный набор гиперпараметров для поиска\n",
    "hyperparams = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV с метрикой F1\n",
    "clf_dtc = RandomizedSearchCV(\n",
    "    model_dtc,\n",
    "    hyperparams,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "clf_dtc.fit(X_train, y_train)\n",
    "\n",
    "# Вывод лучших гиперпараметров\n",
    "print(\"Лучшие гиперпараметры:\")\n",
    "print(clf_dtc.best_params_)\n",
    "\n",
    "# Лучшая модель\n",
    "model_dtc = clf_dtc.best_estimator_\n",
    "\n",
    "# Оценка F1-метрики\n",
    "f1_dtc = clf_dtc.best_score_\n",
    "\n",
    "print('F1 для DecisionTreeClassifier =', f1_dtc.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn757JHUxFsr"
   },
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nVNLoCmxKc0",
    "outputId": "4415a9e8-4a7b-4597-80e4-cc1aa49b0a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 для CatBoostClassifier = 0.73\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели CatBoostClassifier\n",
    "model_cbc = CatBoostClassifier(verbose=False, iterations=100)\n",
    "\n",
    "# Обучение модели\n",
    "model_cbc.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "prediction_cbc = model_cbc.predict(X_test)\n",
    "\n",
    "# Оценка F1-метрики\n",
    "f1_cbc = f1_score(y_test, prediction_cbc)\n",
    "\n",
    "# Вывод F1-метрики\n",
    "print('F1 для CatBoostClassifier =', f1_cbc.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbg6r9kF939B"
   },
   "source": [
    "## Выбор лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "bfpPI3z67_Um"
   },
   "outputs": [],
   "source": [
    "# Функция для измерения времени выполнения кода\n",
    "def measure_time(func):\n",
    "    start = time.time()\n",
    "    result = func()\n",
    "    end = time.time()\n",
    "    return result, (end - start)\n",
    "\n",
    "# Оценка моделей\n",
    "models_results = {}\n",
    "f1_scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylHVSx5B9-H8",
    "outputId": "32a29873-b78e-4480-b935-d8a3db44b8c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение F1 для LogisticRegression по кросс-валидации: 0.76\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "train_time_lr = measure_time(lambda: model_lr.fit(X_train, y_train))\n",
    "\n",
    "# Кросс-валидационная оценка модели\n",
    "f1_scores = cross_val_score(model_lr, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Среднее значение F1 с кросс-валидацией\n",
    "f1_lr = f1_scores.mean()\n",
    "\n",
    "# Измерение времени предсказания на обучающих данных\n",
    "pred_time_lr = measure_time(lambda: cross_val_predict(model_lr, X_train, y_train, cv=5))\n",
    "\n",
    "# Запись результатов модели\n",
    "models_results['LogisticRegression'] = {\n",
    "    'model': model_lr,\n",
    "    'f1': f1_lr,\n",
    "    'train_time': train_time_lr,\n",
    "    'pred_time': pred_time_lr\n",
    "}\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Среднее значение F1 для LogisticRegression по кросс-валидации: {f1_lr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzVPDtCM-zVS",
    "outputId": "a5e1c5b2-b423-4748-8efc-e7b35832beb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение F1 для DecisionTreeClassifier по кросс-валидации: 0.60\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "train_time_dtc = measure_time(lambda: model_dtc.fit(X_train, y_train))\n",
    "\n",
    "# Кросс-валидационная оценка модели\n",
    "f1_scores = cross_val_score(model_dtc, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Среднее значение F1 с кросс-валидацией\n",
    "f1_dtc = f1_scores.mean()\n",
    "\n",
    "# Измерение времени предсказания на обучающих данных\n",
    "pred_time_dtc = measure_time(lambda: cross_val_predict(model_dtc, X_train, y_train, cv=5))\n",
    "\n",
    "# Запись результатов модели\n",
    "models_results['DecisionTreeClassifier'] = {\n",
    "    'model': model_dtc,\n",
    "    'f1': f1_dtc,\n",
    "    'train_time': train_time_dtc,\n",
    "    'pred_time': pred_time_dtc\n",
    "}\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Среднее значение F1 для DecisionTreeClassifier по кросс-валидации: {f1_dtc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRutz7y0_OyW",
    "outputId": "e0431084-b04e-4189-e262-9543bf306e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение F1 для CatBoostClassifier по кросс-валидации: 0.73\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier\n",
    "train_time_cbc = measure_time(lambda: model_cbc.fit(X_train, y_train))\n",
    "\n",
    "# Кросс-валидационная оценка модели\n",
    "f1_scores = cross_val_score(model_cbc, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Среднее значение F1 с кросс-валидацией\n",
    "f1_cbc = f1_scores.mean()\n",
    "\n",
    "# Измерение времени предсказания на обучающих данных\n",
    "pred_time_cbc = measure_time(lambda: cross_val_predict(model_cbc, X_train, y_train, cv=5))\n",
    "\n",
    "# Запись результатов модели\n",
    "models_results['CatBoostClassifier'] = {\n",
    "    'model': model_cbc,\n",
    "    'f1': f1_cbc,\n",
    "    'train_time': train_time_cbc,\n",
    "    'pred_time': pred_time_cbc\n",
    "}\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Среднее значение F1 для CatBoostClassifier по кросс-валидации: {f1_cbc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "jVYRfsYh_jnP"
   },
   "outputs": [],
   "source": [
    "# Сравнение моделей\n",
    "def score(model):\n",
    "    return (\n",
    "        # Нормализация F1: отношение F1 модели к минимальному F1 среди всех моделей\n",
    "        (model['f1'] / min(m['f1'] for m in models_results.values())) +\n",
    "        # Нормализация времени обучения: отношение времени обучения модели к минимальному времени среди всех моделей\n",
    "        (model['train_time'][1] / min(m['train_time'][1] for m in models_results.values())) +\n",
    "        # Нормализация времени предсказания: отношение времени предсказания модели к минимальному времени среди всех моделей\n",
    "        (model['pred_time'][1] / min(m['pred_time'][1] for m in models_results.values()))\n",
    "    ) / 3 # Среднее значение нормализованных критериев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miAwDyvD_1Lz",
    "outputId": "4d9ad60b-b883-4554-fb95-cb2bea539d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 1.0850579374629767\n",
      "DecisionTreeClassifier: 4.362984356495228\n",
      "CatBoostClassifier: 44.146644615990944\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем оценку для каждой модели\n",
    "scores = {k: score(v) for k, v in models_results.items()}\n",
    "\n",
    "# Выводим название модели и её оценку\n",
    "for model, score in scores.items():\n",
    "    print(f'{model}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfcXU3UD_68b",
    "outputId": "768fa529-23d1-4ab3-c83f-7b06f75a914c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшей моделью оказалась LogisticRegression\n",
      "F1-score на тестовой выборке = 0.752642953098534\n",
      "Время предсказания на тестовой выборке = 0.014154672622680664 секунд\n"
     ]
    }
   ],
   "source": [
    "# Выбор лучшей модели и тестирование её на тестовой выборке\n",
    "best_model_name = min(scores, key=scores.get)\n",
    "best_model = models_results[best_model_name]['model']\n",
    "\n",
    "# Окончательная оценка на тестовой выборке\n",
    "predictions, test_time = measure_time(lambda: best_model.predict(X_test))\n",
    "f1_score = f1_score(y_test, predictions)\n",
    "\n",
    "print(f'Лучшей моделью оказалась {best_model_name}')\n",
    "print(f'F1-score на тестовой выборке = {f1_score}')\n",
    "print(f'Время предсказания на тестовой выборке = {test_time} секунд')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6h4vSxzD_K2"
   },
   "source": [
    "## Общие выводы\n",
    "\n",
    "1. **Загрузка и изучение данных:**\n",
    "\n",
    "    Были загружены комментарии и оценка их токсичности. Проведён первоначальный анализ данных.\n",
    "\n",
    "\n",
    "2. **Подготовка данных:**\n",
    "\n",
    "- Данные очищены и лемматизированы;\n",
    "- Применена TF-IDF векторизация к обучающей и тестовой выборке.\n",
    "\n",
    "\n",
    "3. **Обучение моделей:**\n",
    "\n",
    "    Были обучены несколько моделей машинного обучения: LogisticRegression, DecisionTreeClassifier и CatBoostClassifier. Модели были обучены на подготовленных данных с последующей оценкой их точности.\n",
    "\n",
    "\n",
    "4. **Сравнение моделей и выбор лучшей:**\n",
    "\n",
    "    Проведено сравнение моделей на основе метрики accuracy. Выбрана модель, показавшая наилучшие результаты, с минимальным временем обучения и предсказания.\n",
    "\n",
    "\n",
    "5. **Итоговые выводы:**\n",
    "\n",
    "    В результате проведённого анализа и моделирования была выбрана лучшая модель (LogisticRegression) с accuracy на тестовой выборке = 0.95, которая способна определить токсичные комментарии."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2883,
    "start_time": "2024-09-22T06:05:55.533Z"
   },
   {
    "duration": 2643,
    "start_time": "2024-09-22T06:05:58.419Z"
   },
   {
    "duration": 905,
    "start_time": "2024-09-22T06:06:01.064Z"
   },
   {
    "duration": 2479,
    "start_time": "2024-09-22T06:06:01.971Z"
   },
   {
    "duration": 32,
    "start_time": "2024-09-22T06:06:04.453Z"
   },
   {
    "duration": 22,
    "start_time": "2024-09-22T06:06:04.487Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-22T06:06:04.510Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-22T06:06:04.523Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-22T06:06:04.537Z"
   },
   {
    "duration": 479,
    "start_time": "2024-09-22T06:06:14.815Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-22T06:09:04.885Z"
   },
   {
    "duration": 415,
    "start_time": "2024-09-22T06:09:09.410Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-22T06:09:25.871Z"
   },
   {
    "duration": 562376,
    "start_time": "2024-09-22T06:09:29.898Z"
   },
   {
    "duration": 2583,
    "start_time": "2024-09-22T06:23:19.470Z"
   },
   {
    "duration": 2594,
    "start_time": "2024-09-22T06:23:22.056Z"
   },
   {
    "duration": 201,
    "start_time": "2024-09-22T06:23:24.651Z"
   },
   {
    "duration": 2681,
    "start_time": "2024-09-22T06:23:24.854Z"
   },
   {
    "duration": 33,
    "start_time": "2024-09-22T06:23:27.538Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-22T06:23:27.572Z"
   },
   {
    "duration": 36,
    "start_time": "2024-09-22T06:23:27.582Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-22T06:23:27.620Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-22T06:23:27.625Z"
   },
   {
    "duration": 154854,
    "start_time": "2024-09-22T06:23:27.635Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-22T06:26:02.491Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-22T06:26:02.493Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-22T06:26:41.512Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-22T06:29:38.232Z"
   },
   {
    "duration": 5800,
    "start_time": "2024-09-22T13:45:48.787Z"
   },
   {
    "duration": 11111,
    "start_time": "2024-09-22T13:45:54.589Z"
   },
   {
    "duration": 514,
    "start_time": "2024-09-22T13:46:05.702Z"
   },
   {
    "duration": 2553,
    "start_time": "2024-09-22T13:46:06.218Z"
   },
   {
    "duration": 33,
    "start_time": "2024-09-22T13:46:08.773Z"
   },
   {
    "duration": 24,
    "start_time": "2024-09-22T13:46:08.808Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-22T13:46:08.833Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-22T13:46:08.840Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-22T13:46:08.850Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-22T13:46:08.856Z"
   },
   {
    "duration": 338,
    "start_time": "2024-09-22T13:46:08.865Z"
   },
   {
    "duration": 1304,
    "start_time": "2024-09-22T13:47:23.746Z"
   }
  ],
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
